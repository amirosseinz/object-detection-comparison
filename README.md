# Object Detection Model Comparison Platform

> Microservices-based REST API for benchmarking SSD vs. Faster R-CNN inference on wildlife imagery, with real-time performance metrics and side-by-side visualization

**Tech Stack**: TensorFlow Serving â€¢ Flask â€¢ Docker â€¢ SSD ResNet50 FPN â€¢ Faster R-CNN ResNet101

---

## Problem Statement

Selecting the optimal object detection model requires quantifying the speed-accuracy trade-off on domain-specific data. This platform enables direct comparison of two production architecturesâ€”SSD (single-shot, optimized for latency) and Faster R-CNN (region-based, optimized for precision)â€”against a custom African wildlife dataset (Ostrich, Warthog, Lion). Results inform deployment decisions: edge scenarios prioritize inference speed, while conservation monitoring may favor detection accuracy.

---

## Key Features

- **Dual-model inference pipeline**: Simultaneous processing through SSD ResNet50 FPN and Faster R-CNN ResNet101 via TensorFlow Serving
- **Real-time performance metrics**: Per-image inference timing, detection counts, and confidence scores logged to persistent storage
- **Side-by-side visualization**: Bounding box overlays rendered with PIL, enabling direct visual comparison of detection quality
- **RESTful API**: JSON endpoints for programmatic access to metrics, comparison data, and health status
- **Containerized microservices**: Three-container architecture (Flask app + 2Ã— TensorFlow Serving) with GPU support via alternate compose file
- **Request tracing**: UUID-based request IDs propagated through logs for debugging distributed inference workflows

---

## System Design

```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚      User Browser        â”‚
                              â”‚   (Upload / Results UI)  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚ HTTP
                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Docker Compose Network                              â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Flask Application (Port 80)                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Routes     â”‚  â”‚  Inference   â”‚  â”‚    Image     â”‚  â”‚  Results    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  /inference â”‚  â”‚  Orchestratorâ”‚  â”‚  Processing  â”‚  â”‚  Storage    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  /results   â”‚  â”‚              â”‚  â”‚  (PIL/NumPy) â”‚  â”‚  (CSV/JSON) â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  /metrics   â”‚  â”‚              â”‚  â”‚              â”‚  â”‚             â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                    â”‚                               â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚             â–¼                                               â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  TensorFlow Serving     â”‚               â”‚  TensorFlow Serving     â”‚       â”‚
â”‚  â”‚  SSD ResNet50 FPN       â”‚               â”‚  Faster R-CNN ResNet101 â”‚       â”‚
â”‚  â”‚  (Port 8501)            â”‚               â”‚  (Port 8502)            â”‚       â”‚
â”‚  â”‚  ~2-3s inference (CPU)  â”‚               â”‚  ~2-4s inference (CPU)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Components**:
- **API Layer**: Flask 2.0 with CORS support, request ID middleware, and structured error handling (400/404/500/503)
- **Inference Orchestrator**: Parallel requests to both TensorFlow Serving endpoints with 120s timeout and health monitoring
- **Image Processor**: PIL-based preprocessing, confidence filtering (threshold: 0.5), bounding box rendering with cross-platform font support
- **Results Storage**: CSV aggregate metrics + per-image JSON detection details, supporting analytics aggregation

---

## Models Implemented

| Model | Architecture | Backbone | Input Size | Avg. Inference (CPU) | Use Case |
|-------|--------------|----------|------------|---------------------|----------|
| SSD | Single Shot MultiBox Detector | ResNet50 + FPN | 640Ã—640 | ~2-3s | Lower latency, real-time applications |
| Faster R-CNN | Region-based CNN | ResNet101 | 640Ã—640 | ~2-4s | Higher precision, detailed analysis |

**Detection Classes** (Custom-trained):
| Class ID | Scientific Name | Common Name |
|----------|-----------------|-------------|
| 1 | *Struthio camelus* | Ostrich |
| 2 | *Phacochoerus africanus* | Warthog |
| 3 | *Panthera leo* | Lion |

---

## Quick Start API

**Upload & Detect**:
```bash
curl -X POST http://localhost/inference \
  -F "file=@wildlife_image.jpg"
```

**Get Comparison Results**:
```bash
curl -H "Accept: application/json" \
  http://localhost/api/comparison/{image_id}
```

**Response**:
```json
{
  "image": {
    "image_id": "7b98b3c1-59af-4796-86aa-5b3f3468d42d",
    "filename": "lion-pride.jpg",
    "file_size": 1464721
  },
  "inferences": {
    "model_a": {
      "inference_time": 2.72,
      "detection_count": 4,
      "detections": [
        {"class_name": "Pantheraleo", "confidence": 0.94, "bbox_normalized": [0.12, 0.08, 0.45, 0.67]}
      ]
    },
    "model_b": {
      "inference_time": 2.78,
      "detection_count": 5,
      "detections": [...]
    }
  }
}
```

**Health Check**:
```bash
curl http://localhost/health
```

ðŸ“˜ **Full API documentation**: [docs/API.md](docs/API.md)

---

## Setup

### Prerequisites

- [Docker](https://www.docker.com/get-started) (v20.10+) and Docker Compose
- 4GB+ RAM available for containers
- **For GPU**: NVIDIA GPU with [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) installed

### Clone Repository

```bash
git clone https://github.com/amirosseinz/object-detection-comparison.git
cd object-detection-comparison
```

### Docker Compose Files

| File | TensorFlow Serving Image | Use Case |
|------|--------------------------|----------|
| `docker-compose.yml` | `tensorflow/serving:latest` | CPU-only deployment (default) |
| `docker-compose.gpu.yml` | `tensorflow/serving:latest-gpu` | GPU-accelerated inference (NVIDIA) |

### CPU Deployment (Default)

For systems without a dedicated GPU or for development/testing:

```bash
# Build and start all containers
docker compose up --build

# Or run in detached mode
docker compose up --build -d

# View logs
docker compose logs -f
```

### GPU Deployment (NVIDIA)

For faster inference on systems with NVIDIA GPU:

```bash
# Verify NVIDIA runtime is available
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# Build and start with GPU support
docker compose -f docker-compose.gpu.yml up --build

# Or run in detached mode
docker compose -f docker-compose.gpu.yml up --build -d
```

**GPU Requirements**:
- NVIDIA GPU with CUDA support
- NVIDIA Driver 450.80.02+
- NVIDIA Container Toolkit installed
- Docker configured with `nvidia` runtime

### Verify Deployment

```bash
# Check container status
docker compose ps

# Test health endpoint
curl http://localhost/health

# Test TensorFlow Serving models
curl http://localhost:8501/v1/models/ssd
curl http://localhost:8502/v1/models/faster_rcnn
```

### Stop Services

```bash
# CPU deployment
docker compose down

# GPU deployment
docker compose -f docker-compose.gpu.yml down

# Remove volumes and images (full cleanup)
docker compose down -v --rmi all
```

### Local Development (Without Docker)

```bash
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate
pip install -r requirements.txt

# Start TF Serving containers separately, then:
export TF_SERVING_URL_MODEL_A=http://localhost:8501/v1/models/ssd:predict
export TF_SERVING_URL_MODEL_B=http://localhost:8502/v1/models/faster_rcnn:predict
python app.py
```

ðŸš€ **Production deployment guide**: [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)

---

## Technical Decisions & Trade-offs

| Decision | Rationale |
|----------|-----------|
| **Separate TF Serving containers** | Independent scaling, isolated failure domains, different memory/CPU requirements per model architecture |
| **Flask over FastAPI** | Template rendering for web UI, mature ecosystem, simpler session management; async not required for synchronous inference |
| **CSV + JSON storage** | Portability for analysis, no database setup required; appropriate for demonstration scope (production would use PostgreSQL + S3) |
| **50% confidence threshold** | Balances precision/recall for wildlife domain; configurable via `CONFIDENCE_THRESHOLD` |
| **Request ID middleware** | Enables distributed tracing across Flask â†’ TF Serving logs for debugging inference failures |
| **Cross-platform font loading** | Ensures bounding box labels render correctly across Windows, macOS, and Linux containers |

---

## Observed Performance

**Test Environment**: Docker containers on CPU (results vary with hardware and image complexity)

Based on logged inference data across 40+ processed images:

| Metric | SSD (Model A) | Faster R-CNN (Model B) |
|--------|---------------|------------------------|
| Median Inference Time | ~2.0s | ~2.3s |
| Range | 0.8s - 5.7s | 0.3s - 7.0s |
| Typical Detection Count | 1-3 per image | 1-5 per image |

**Observations**:
- First inference after container start incurs model loading overhead (~5-7s)
- Faster R-CNN occasionally detects additional objects at lower confidence
- Large images (>1MB) increase preprocessing time proportionally

---

## Professional Skills Demonstrated

**ML Engineering**:
- Integration of pre-trained TensorFlow SavedModels with TensorFlow Serving inference API
- Confidence thresholding and non-maximum suppression handling
- Bounding box coordinate transformation (normalized â†’ pixel space)

**Backend Development**:
- RESTful API design with proper HTTP status codes and content negotiation
- File upload validation (extension whitelist, MIME checking, 16MB limit)
- Structured logging with request correlation IDs

**DevOps/Infrastructure**:
- Multi-container orchestration with Docker Compose
- Service health checks for container orchestration readiness
- GPU deployment configuration with NVIDIA runtime support
- Environment-based configuration management

**Software Engineering Practices**:
- Error handling with graceful degradation (app remains healthy if TF Serving unavailable)
- Directory structure with separation of concerns (routes, processing, storage)
- Cross-platform compatibility (font loading, path handling)

---

## Repository Structure

```
ObjectDetectionComparisonFlaskApp/
â”œâ”€â”€ app.py                    # Flask application (706 lines) - routes, inference, metrics
â”œâ”€â”€ docker-compose.yml        # CPU deployment orchestration
â”œâ”€â”€ docker-compose.gpu.yml    # GPU deployment with NVIDIA runtime
â”œâ”€â”€ Dockerfile                # Flask container (Python 3.8-slim)
â”œâ”€â”€ requirements.txt          # Dependencies: Flask, Pillow, NumPy, requests
â”œâ”€â”€ detection_results.csv     # Aggregate inference metrics
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ label_map.pbtxt       # Class ID â†’ name mapping
â”‚   â”œâ”€â”€ ssd/                  # SSD SavedModel directory
â”‚   â””â”€â”€ faster_rcnn/          # Faster R-CNN SavedModel directory
â”œâ”€â”€ results_details/          # Per-image detection JSON files
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ classified/           # Processed images with bounding boxes
â”‚   â”œâ”€â”€ css/                  # Tailwind-based styling
â”‚   â””â”€â”€ js/                   # Chart.js visualizations
â”œâ”€â”€ templates/                # Jinja2 templates (index, results, metrics, errors)
â””â”€â”€ docs/
    â”œâ”€â”€ API.md                # Endpoint documentation
    â”œâ”€â”€ ARCHITECTURE.md       # System design details
    â””â”€â”€ DEPLOYMENT.md         # Cloud deployment guides (AWS, GCP, Azure)
```

---

## Future Enhancements

- **Batch inference endpoint**: Process multiple images in single request for throughput optimization
- **Model versioning**: A/B testing framework for comparing model iterations
- **Prometheus metrics**: Export inference latency histograms for Grafana dashboards
- **TensorRT optimization**: INT8 quantization for edge deployment scenarios

---

## Contributing

For questions or collaboration:
- Open an issue for bugs or feature requests
- See [ARCHITECTURE.md](docs/ARCHITECTURE.md) for system design context
- See [API.md](docs/API.md) for endpoint specifications

---

**License**: MIT
